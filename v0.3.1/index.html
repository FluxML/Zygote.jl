<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · Zygote</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-36890222-9', 'auto');
ga('send', 'pageview');
</script><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Zygote</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>Home</a><ul class="internal"><li><a class="toctext" href="#Setup-1">Setup</a></li><li><a class="toctext" href="#Taking-Gradients-1">Taking Gradients</a></li><li><a class="toctext" href="#Structs-and-Types-1">Structs and Types</a></li><li><a class="toctext" href="#Gradients-of-ML-models-1">Gradients of ML models</a></li></ul></li><li><a class="toctext" href="adjoints/">Custom Adjoints</a></li><li><a class="toctext" href="utils/">Utilities</a></li><li><a class="toctext" href="complex/">Complex Differentiation</a></li><li><a class="toctext" href="flux/">Flux</a></li><li><a class="toctext" href="profiling/">Profiling</a></li><li><a class="toctext" href="internals/">Internals</a></li><li><a class="toctext" href="glossary/">Glossary</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Home</a></li></ul><a class="edit-page" href="https://github.com/FluxML/Zygote.jl/blob/master/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Home</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Zygote-1" href="#Zygote-1">Zygote</a></h1><p>Welcome! Zygote extends the Julia language to support <a href="https://fluxml.ai/2019/02/07/what-is-differentiable-programming.html">differentiable programming</a>. With Zygote you can write down any Julia code you feel like – including using existing Julia packages – then get gradients and optimise your program. Deep learning, ML and probabilistic programming are all different kinds of differentiable programming that you can do with Zygote.</p><p>At least, that&#39;s the idea. We&#39;re still in beta so expect some adventures.</p><h2><a class="nav-anchor" id="Setup-1" href="#Setup-1">Setup</a></h2><p>Zygote is still moving quickly and it&#39;s best to work from the development branches. Run this in a Julia session:</p><pre><code class="language-julia">using Pkg; pkg&quot;add Zygote#master&quot;</code></pre><h2><a class="nav-anchor" id="Taking-Gradients-1" href="#Taking-Gradients-1">Taking Gradients</a></h2><p>Zygote is easy to understand since, at its core, it has a one-function API (<code>forward</code>), along with a few simple conveniences. Before explaining <code>forward</code>, we&#39;ll look at the higher-level function <code>gradient</code>.</p><p><code>gradient</code> calculates derivatives. For example, the derivative of <span>$3x^2 + 2x + 1$</span> is <span>$6x + 2$</span>, so when <code>x = 5</code>, <code>dx = 32</code>.</p><pre><code class="language-julia">julia&gt; using Zygote

julia&gt; gradient(x -&gt; 3x^2 + 2x + 1, 5)
(32,)</code></pre><p><code>gradient</code> returns a tuple, with a gradient for each argument to the function.</p><pre><code class="language-julia">julia&gt; gradient((a, b) -&gt; a*b, 2, 3)
(3, 2)</code></pre><p>This will work equally well if the arguments are arrays, structs, or any other Julia type, but the function should return a scalar (like a loss or objective <span>$l$</span>, if you&#39;re doing optimisation / ML).</p><pre><code class="language-julia">julia&gt; W = rand(2, 3); x = rand(3);

julia&gt; gradient(W -&gt; sum(W*x), W)[1]
2×3 Array{Float64,2}:
 0.0462002  0.817608  0.979036
 0.0462002  0.817608  0.979036

julia&gt; gradient(x -&gt; 3x^2 + 2x + 1, 1//4)
(7//2,)</code></pre><p>Control flow is fully supported, including recursion.</p><pre><code class="language-julia">julia&gt; function pow(x, n)
         r = 1
         for i = 1:n
           r *= x
         end
         return r
       end
pow (generic function with 1 method)

julia&gt; gradient(x -&gt; pow(x, 3), 5)
(75,)

julia&gt; pow2(x, n) = n &lt;= 0 ? 1 : x*pow(x, n-1)
pow2 (generic function with 1 method)

julia&gt; gradient(x -&gt; pow2(x, 3), 5)
(75,)</code></pre><p>Data structures are also supported, including mutable ones like dictionaries. Arrays are currently immutable, though <a href="https://github.com/FluxML/Zygote.jl/pull/75">this may change</a> in future.</p><pre><code class="language-julia">julia&gt; d = Dict()
Dict{Any,Any} with 0 entries

julia&gt; gradient(5) do x
         d[:x] = x
         d[:x] * d[:x]
       end
(10,)

julia&gt; d[:x]
5</code></pre><h2><a class="nav-anchor" id="Structs-and-Types-1" href="#Structs-and-Types-1">Structs and Types</a></h2><p>Julia makes it easy to work with custom types, and Zygote makes it easy to differentiate them. For example, given a simple <code>Point</code> type:</p><pre><code class="language-julia">import Base: +, -

struct Point
  x::Float64
  y::Float64
end

a::Point + b::Point = Point(a.x + b.x, a.y + b.y)
a::Point - b::Point = Point(a.x - b.x, a.y - b.y)
dist(p::Point) = sqrt(p.x^2 + p.y^2)</code></pre><pre><code class="language-julia">julia&gt; a = Point(1, 2)
Point(1.0, 2.0)

julia&gt; b = Point(3, 4)
Point(3.0, 4.0)

julia&gt; dist(a + b)
7.211102550927978

julia&gt; gradient(a -&gt; dist(a + b), a)[1]
(x = 0.5547001962252291, y = 0.8320502943378437)</code></pre><p>Zygote&#39;s default representation of the &quot;point adjoint&quot; is a named tuple with gradients for both fields, but this can of course be customised too.</p><p>This means we can do something very powerful: differentiating through Julia libraries, even if they weren&#39;t designed for this. For example, <code>colordiff</code> might be a smarter loss function on colours than simple mean-squared-error:</p><pre><code class="language-julia">julia&gt; using Colors

julia&gt; colordiff(RGB(1, 0, 0), RGB(0, 1, 0))
86.60823557376344

julia&gt; gradient(colordiff, RGB(1, 0, 0), RGB(0, 1, 0))
((r = 0.4590887719632896, g = -9.598786801605689, b = 14.181383399012862), (r = -1.7697549557037275, g = 28.88472330558805, b = -0.044793892637761346))</code></pre><h2><a class="nav-anchor" id="Gradients-of-ML-models-1" href="#Gradients-of-ML-models-1">Gradients of ML models</a></h2><p>It&#39;s easy to work with even very large and complex models, and there are few ways to do this. Autograd-style models pass around a collection of weights.</p><pre><code class="language-julia">julia&gt; linear(θ, x) = θ[:W] * x .+ θ[:b]
linear (generic function with 1 method)

julia&gt; x = rand(5);

julia&gt; θ = Dict(:W =&gt; rand(2, 5), :b =&gt; rand(2))
Dict{Any,Any} with 2 entries:
  :b =&gt; [0.0430585, 0.530201]
  :W =&gt; [0.923268 … 0.589691]

# Alternatively, use a named tuple or struct rather than a dict.
# θ = (W = rand(2, 5), b = rand(2))

julia&gt; θ̄ = gradient(θ -&gt; sum(linear(θ, x)), θ)[1]
Dict{Any,Any} with 2 entries:
  :b =&gt; [1.0, 1.0]
  :W =&gt; [0.628998 … 0.433006]</code></pre><p>An extension of this is the Flux-style model in which we use call overloading to combine the weight object with the forward pass (equivalent to a closure).</p><pre><code class="language-julia">julia&gt; struct Linear
         W
         b
       end

julia&gt; (l::Linear)(x) = l.W * x .+ l.b

julia&gt; model = Linear(rand(2, 5), rand(2))
Linear([0.267663 … 0.334385], [0.0386873, 0.0203294])

julia&gt; dmodel = gradient(model -&gt; sum(model(x)), model)[1]
(W = [0.652543 … 0.683588], b = [1.0, 1.0])</code></pre><p>Zygote also support one more way to take gradients, via <em>implicit parameters</em> – this is a lot like autograd-style gradients, except we don&#39;t have to thread the parameter collection through all our code.</p><pre><code class="language-julia">julia&gt; W = rand(2, 5); b = rand(2);

julia&gt; linear(x) = W * x .+ b
linear (generic function with 2 methods)

julia&gt; grads = gradient(() -&gt; sum(linear(x)), Params([W, b]))
Grads(...)

julia&gt; grads[W], grads[b]
([0.652543 … 0.683588], [1.0, 1.0])</code></pre><p>However, implicit parameters exist mainly for compatibility with Flux&#39;s current AD; it&#39;s recommended to use the other approaches unless you need this.</p><footer><hr/><a class="next" href="adjoints/"><span class="direction">Next</span><span class="title">Custom Adjoints</span></a></footer></article></body></html>
